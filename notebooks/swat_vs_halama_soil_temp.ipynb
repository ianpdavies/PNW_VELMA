{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing SWAT-derived vs HALAMA (Penumbra) surface and soil temperature models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import __init__\n",
    "import scripts.config as config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from natsort import natsorted\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "\n",
    "XSMALL_SIZE = 6\n",
    "SMALL_SIZE = 7\n",
    "MEDIUM_SIZE = 9\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams['figure.dpi'] = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and format observed data (2003-2007 runoff)\n",
    "\n",
    "input_dir = config.velma_data\n",
    "results_dir = config.data_path.parents[0] / 'results'\n",
    "sims = ['ellsworth_baseline_03_07_21', 'ellsworth_baseline_03_07_24']\n",
    "\n",
    "runoff_start = pd.to_datetime('01-01-2003')\n",
    "runoff_end = pd.to_datetime('12-31-2007')\n",
    "nse_start = pd.to_datetime('01-01-2004')\n",
    "nse_end = pd.to_datetime('12-31-2007')\n",
    "\n",
    "start = pd.to_datetime('01-01-2004')\n",
    "end = pd.to_datetime('12-31-2007')\n",
    "\n",
    "# Import VELMA outputs\n",
    "\n",
    "results = []\n",
    "for sim in sims:\n",
    "    sim_dir = results_dir / sim\n",
    "    velma_results = pd.read_csv(sim_dir / 'DailyResults.csv')\n",
    "    \n",
    "    # Format datetime of results\n",
    "    jday_pad = velma_results['Day'].apply(lambda x: str(x).zfill(3))\n",
    "    str_year = velma_results['Year'].apply(lambda x: str(x))\n",
    "    velma_results['year_jday'] = str_year + jday_pad\n",
    "    velma_results.index = pd.to_datetime(velma_results['year_jday'], format='%Y%j')\n",
    "    velma_results = velma_results[(velma_results.index >= start) & (velma_results.index <= end)]\n",
    "    results.append(velma_results)\n",
    "\n",
    "swat_results = results[0]\n",
    "halama_results = results[1]\n",
    "\n",
    "# Stream temperature observations\n",
    "streamtemp_path = config.data_path / 'hydrology' / 'ellsworth' / 'wa_ecy_gauge' / 'stream_temp' / 'ells_streamtemp_2003_2008.csv'\n",
    "streamtemp_obs = pd.read_csv(streamtemp_path, usecols=['date', 'water_temp'], parse_dates=True, index_col=0)\n",
    "streamtemp_obs['doy'], streamtemp_obs['year'] = streamtemp_obs.index.dayofyear, streamtemp_obs.index.year\n",
    "streamtemp_obs = streamtemp_obs[(streamtemp_obs.index >= start) & (streamtemp_obs.index <= end)]\n",
    "\n",
    "# Stream temperature quality codes\n",
    "streamtemp_path = config.data_path  / 'hydrology' / 'ellsworth' / 'wa_ecy_gauge' / 'stream_temp' / 'ells_streamtemp_2003_2008.csv'\n",
    "stream_temp_quality = pd.read_csv(streamtemp_path, usecols=['date', 'quality'], parse_dates=True, index_col=0)\n",
    "stream_temp_quality['doy'], stream_temp_quality['year'] = stream_temp_quality.index.dayofyear, stream_temp_quality.index.year\n",
    "stream_temp_quality = stream_temp_quality[(stream_temp_quality.index >= start) & (stream_temp_quality.index <= end)]\n",
    "\n",
    "# Runoff observations\n",
    "runoff_path = input_dir / 'runoff' / 'ellsworth_Q_2003_2007_dummy.csv'\n",
    "runoff_obs = pd.read_csv(runoff_path, names=['runoff_obs'])\n",
    "runoff_obs.index = pd.date_range(runoff_start, runoff_end)\n",
    "runoff_obs['doy'], runoff_obs['year'] = runoff_obs.index.dayofyear, runoff_obs.index.year\n",
    "runoff_obs = runoff_obs[(runoff_obs.index >= start) & (runoff_obs.index <= end)]\n",
    "\n",
    "# Runoff quality codes\n",
    "flow_path = config.streamflow\n",
    "quality = pd.read_csv(flow_path, usecols=['Date', 'Quality'], parse_dates=True, index_col=0)\n",
    "quality = quality[(quality.index >= start) & (quality.index <= end)]\n",
    "\n",
    "# Precipitation\n",
    "precip_path = input_dir / 'precip' / 'PRISM_gauge_avg_ppt_2003_2019.csv'\n",
    "forcing_start = pd.to_datetime('01-01-2003')\n",
    "forcing_end = pd.to_datetime('12-31-2019')                     \n",
    "precip = pd.read_csv(precip_path, names=['precip'])\n",
    "precip.index = pd.date_range(forcing_start, forcing_end)\n",
    "precip['doy'], precip['year'] = precip.index.dayofyear, precip.index.year\n",
    "precip = precip[(precip.index >= start) & (precip.index <= end)]\n",
    "\n",
    "# Air temperature\n",
    "temp_path = input_dir / 'temp' / 'ellsworth_temp_2003_2019.csv'\n",
    "temp = pd.read_csv(temp_path, names=['temp'])\n",
    "temp.index = pd.date_range(forcing_start, forcing_end)\n",
    "temp['doy'], temp['year'] = temp.index.dayofyear, temp.index.year\n",
    "temp = temp[(temp.index >= start) & (temp.index <= end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stream temperature from cell writer files\n",
    "\n",
    "# Get paths\n",
    "all_cell_results = []\n",
    "for sim in sims:\n",
    "    cell_paths = []\n",
    "    for file in os.listdir(results_dir / sim):\n",
    "        if file.startswith('Cell_'):\n",
    "            cell_paths.append(file)\n",
    "\n",
    "    nodes = []\n",
    "    for path in cell_paths:\n",
    "        nodes.append(path.split('_')[-1])\n",
    "\n",
    "    cell_paths_sorted = [x for _,x in natsorted(zip(nodes, cell_paths))]\n",
    "\n",
    "    cell_results = []\n",
    "    for path in cell_paths_sorted:\n",
    "        cell_result = pd.read_csv(results_dir / sim / path)\n",
    "        jday_pad = cell_result['Jday'].apply(lambda x: str(x).zfill(3))\n",
    "        str_year = cell_result['Year'].apply(lambda x: str(x))\n",
    "        cell_result['date'] = str_year + jday_pad\n",
    "        rng = pd.to_datetime(cell_result['date'], format='%Y%j')\n",
    "        cell_result.index = rng\n",
    "        cell_result = cell_result[(cell_result.index >= start) & (cell_result.index <= end)]\n",
    "        cell_results.append(cell_result)\n",
    "\n",
    "    all_cell_results.append(cell_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pivot tables\n",
    "\n",
    "outlet_pivots = []\n",
    "for sim in all_cell_results:\n",
    "    piv = pd.pivot_table(sim[0], index=['Jday'], columns=['Year'], \n",
    "                         values='Water_Surface_Temperature(degrees_C)', dropna=False)\n",
    "    outlet_pivots.append(piv)\n",
    "\n",
    "streamtemp_obs_yearly = pd.pivot_table(streamtemp_obs, index=['doy'], columns=['year'],\n",
    "                                   values='water_temp', dropna=False)\n",
    "\n",
    "runoff_swat_yearly = pd.pivot_table(swat_results, index=['Day'], columns=['Year'],\n",
    "                                   values='Runoff_All(mm/day)_Delineated_Average', dropna=False)\n",
    "\n",
    "runoff_halama_yearly = pd.pivot_table(halama_results, index=['Day'], columns=['Year'],\n",
    "                                   values='Runoff_All(mm/day)_Delineated_Average', dropna=False)\n",
    "\n",
    "runoff_obs_yearly = pd.pivot_table(runoff_obs, index=['doy'], columns=['year'],\n",
    "                                   values='runoff_obs', dropna=False)\n",
    "\n",
    "streamtemp_swat_yearly = outlet_pivots[0]\n",
    "streamtemp_halama_yearly = outlet_pivots[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a11b75ebea4745aa4405dcf0016d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observed vs. simulated stream temp for gauge\n",
    "years = streamtemp_obs_yearly.columns.get_level_values(0)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(years), figsize=(6, 9))\n",
    "for col, year in enumerate(years):\n",
    "    streamtemp_swat_yearly.iloc[:, col].plot(ax=axes[col], label='SWAT', linewidth=1)\n",
    "    streamtemp_halama_yearly.iloc[:, col].plot(ax=axes[col], label='HALAMA', linewidth=1)\n",
    "    axes[col].set_title(year)\n",
    "    axes[col].set_ylim([0, 20])\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(0, 1.3), fancybox=True, ncol=2)\n",
    "axes[0].set_ylabel('Stream Temperature (C)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HALAMA soil temperature model predicts the same pattern of stream temperature, but about 22% less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnc_velma",
   "language": "python",
   "name": "tnc_velma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
