{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing VELMA simulated runoff output\n",
    "\n",
    "This notebook examines the observed runoff at the Ellsworth Creek gauge (found [here](https://fortress.wa.gov/ecy/eap/flows/station.asp?sta=24M050&historical=true#block2)) and compares it to the runoff simulated in VELMA. The stream gauge data comes with quality tags that describe how far each daily measurement deviates from a rating table for the creek. To determine if these outlier days are causing the discrepancy between simulated and observed runoff, days with very high (>2x rating table) or very low (&lt;1/2x) flows are removed and then imputed with a model trained on non-outlier data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import __init__\n",
    "import scripts.config as config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import datetime\n",
    "from sklearn.svm import SVR\n",
    "import geopandas as gpd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "\n",
    "XSMALL_SIZE = 6\n",
    "SMALL_SIZE = 7\n",
    "MEDIUM_SIZE = 9\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams['figure.dpi'] = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and format observed data (2003-2007 runoff)\n",
    "\n",
    "input_dir = config.velma_data\n",
    "results_dir = config.data_path.parents[0] / 'results' / 'ellsworth_baseline_03_07_12'\n",
    "\n",
    "runoff_path = input_dir / 'runoff' / 'ellsworth_Q_2003_2007_dummy.csv'\n",
    "runoff_start = pd.to_datetime('01-01-2003')\n",
    "runoff_end = pd.to_datetime('12-31-2007')\n",
    "nse_start = pd.to_datetime('01-01-2004')\n",
    "nse_end = pd.to_datetime('12-31-2007')\n",
    "\n",
    "runoff_obs = pd.read_csv(runoff_path, names=['runoff_obs'])\n",
    "runoff_obs.index = pd.date_range(runoff_start, runoff_end)\n",
    "runoff_obs['doy'], runoff_obs['year'] = runoff_obs.index.dayofyear, runoff_obs.index.year\n",
    "runoff_obs = runoff_obs[(runoff_obs.index >= nse_start) & (runoff_obs.index <= nse_end)]\n",
    "\n",
    "flow_path = input_dir.parents[0] / 'hydrology' / 'ellsworth' / 'wa_ecy_gauge' / 'streamflow' / 'ells_streamflow_2003_2008.csv'\n",
    "quality = pd.read_csv(flow_path, usecols=['Date', 'Quality'], parse_dates=True, index_col=0)\n",
    "quality = quality[(quality.index >= nse_start) & (quality.index <= nse_end)]\n",
    "\n",
    "precip_path = input_dir / 'precip' / 'PRISM_gauge_avg_ppt_2003_2019.csv'\n",
    "forcing_start = pd.to_datetime('01-01-2003')\n",
    "forcing_end = pd.to_datetime('12-31-2019')                     \n",
    "precip = pd.read_csv(precip_path, names=['precip'])\n",
    "precip.index = pd.date_range(forcing_start, forcing_end)\n",
    "precip['doy'], precip['year'] = precip.index.dayofyear, precip.index.year\n",
    "precip = precip[(precip.index >= nse_start) & (precip.index <= nse_end)]\n",
    "\n",
    "temp_path = input_dir / 'temp' / 'ellsworth_temp_2003_2019.csv'\n",
    "temp = pd.read_csv(temp_path, names=['temp'])\n",
    "temp.index = pd.date_range(forcing_start, forcing_end)\n",
    "temp['doy'], temp['year'] = temp.index.dayofyear, temp.index.year\n",
    "temp = temp[(temp.index >= nse_start) & (temp.index <= nse_end)]\n",
    "\n",
    "# Import VELMA outputs\n",
    "velma_results = pd.read_csv(results_dir / 'DailyResults.csv')\n",
    "\n",
    "# Format datetime of results\n",
    "jday_pad = velma_results['Day'].apply(lambda x: str(x).zfill(3))\n",
    "str_year = velma_results['Year'].apply(lambda x: str(x))\n",
    "velma_results['year_jday'] = str_year + jday_pad\n",
    "velma_results.index = pd.to_datetime(velma_results['year_jday'], format='%Y%j')\n",
    "velma_results = velma_results[(velma_results.index >= nse_start) & \n",
    "                              (velma_results.index <= nse_end)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean-squared error, root mean-squared error, and R-squared (equal to NSE) of simulated and observed runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSE'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40.02927863395068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'MAE'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.4735576213197965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'RMSE'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6.326869576176727"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'R2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46738813770737575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# velma_results['Runoff_All(mm/day)_Delineated_Average'].sum() / runoff_obs['runoff_obs'].sum()\n",
    "sim_mse = mean_squared_error(runoff_obs['runoff_obs'], velma_results['Runoff_All(mm/day)_Delineated_Average'])\n",
    "sim_mae = mean_absolute_error(runoff_obs['runoff_obs'], velma_results['Runoff_All(mm/day)_Delineated_Average'])\n",
    "display('MSE', sim_mse)\n",
    "display('MAE', sim_mae)\n",
    "display('RMSE', np.sqrt(sim_mse))\n",
    "\n",
    "display('R2', r2_score(runoff_obs['runoff_obs'], velma_results['Runoff_All(mm/day)_Delineated_Average']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group measurements by year\n",
    "runoff_sim_yearly = pd.pivot_table(velma_results, index=['Day'], columns=['Year'],\n",
    "                                   values=['Runoff_All(mm/day)_Delineated_Average'])\n",
    "runoff_obs_yearly = pd.pivot_table(runoff_obs, index=['doy'], columns=['year'], values=['runoff_obs'])\n",
    "precip_yearly = pd.pivot_table(precip, index=['doy'], columns=['year'], values=['precip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observed vs. VELMA simulated runoff\n",
    "\n",
    "VELMA simulated runoff consistently underpredicts the observed runoff during flow peaks. This could be sensor error or may be the flashiness of the stream. There is also a period of very low observed runoff during 2006 that looks fishy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f59802aae2d474096fc989838e8d25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observed vs. VELMA simulated runoff\n",
    "years = runoff_obs_yearly.columns.get_level_values(1)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(years), figsize=(6, 9))\n",
    "for col, year in enumerate(years):\n",
    "    runoff_obs_yearly.iloc[:, col].plot(ax=axes[col], label='Observed', linewidth=1)\n",
    "    runoff_sim_yearly.iloc[:, col].plot(ax=axes[col], label='Simulated', linewidth=1)\n",
    "    axes[col].set_title(year)\n",
    "    axes[col].set_ylim([0, 80])\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(0, 1.3), fancybox=True, ncol=2)\n",
    "axes[0].set_ylabel('Runoff (mm/day)')\n",
    "fig.suptitle('Fig. 1: Observed vs. VELMA simulated runoff')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observed vs. VELMA simulated runoff (with precipitation)\n",
    "\n",
    "Including the precipitation suggests that the low flow values during 2006 are not from a drought but may instead be sensor error, because the precipitation during 2006 is comparable to the other years and shouldn't be causing such a low measurement period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b46654593546a2998c3a34646c7a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Runoff and precip\n",
    "years = runoff_obs_yearly.columns.get_level_values(1)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(years), figsize=(6, 9))\n",
    "\n",
    "for col, year in enumerate(years):\n",
    "    ax2 = axes[col].twinx()\n",
    "    precip_yearly.iloc[:, col].plot(ax=ax2, label='Precip', linewidth=0.5, color='tab:green')\n",
    "    if col == 0:\n",
    "        ax2.set_ylabel('Precipitation (mm/day)')\n",
    "        ax2.legend(loc='upper right', bbox_to_anchor=(1, 1.3), fancybox=True, ncol=1)\n",
    "    runoff_obs_yearly.iloc[:, col].plot(ax=axes[col], label='Observed', linewidth=1)\n",
    "    runoff_sim_yearly.iloc[:, col].plot(ax=axes[col], label='Simulated', linewidth=1)\n",
    "    ax2.invert_yaxis()\n",
    "    axes[col].set_ylim([0, 80])\n",
    "    axes[col].set_title(year)\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(0, 1.3))\n",
    "axes[0].set_ylabel('Runoff (mm/day)')\n",
    "fig.suptitle('Fig. 2: Observed vs. VELMA simulated runoff (with precipitation)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observed vs. VELMA simulated runoff (with precipitation and quality flags for runoff measurements)\n",
    "\n",
    "Here we can add in the quality flags for the runoff data. Each day has a flag, so we'll just include the ones that are the most unreliable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02310f9610e44575a6d202846d06f0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add quality scores below plot\n",
    "\n",
    "colors = sns.color_palette('tab10', 10)\n",
    "\n",
    "quality_edit = quality.copy()\n",
    "\n",
    "quality_edit['doy'], quality_edit['year'] = quality_edit.index.dayofyear, quality_edit.index.year\n",
    "quality_edit_yearly = pd.pivot_table(quality_edit, index=['doy'], columns=['year'], values=['Quality'])\n",
    "quality2 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                        [-2, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "quality3 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                        [np.nan, -2, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "quality8 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                       [np.nan, np.nan, -2, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "quality10 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                        [np.nan, np.nan, np.nan, -2, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "quality50 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                        [np.nan, np.nan, np.nan, np.nan, -2, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "quality77 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                        [np.nan, np.nan, np.nan, np.nan, np.nan, -2, np.nan, np.nan, np.nan, np.nan])\n",
    "quality160 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                         [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, -2, np.nan, np.nan, np.nan])\n",
    "quality161 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                         [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, -2, np.nan, np.nan])\n",
    "quality179 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                         [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, -2, np.nan])\n",
    "quality254 = quality_edit_yearly.replace([2, 3, 8, 10, 50, 77, 160, 161, 179, 254],\n",
    "                                         [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, -2])\n",
    "\n",
    "years = runoff_obs_yearly.columns.get_level_values(1)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(years), figsize=(6, 9))\n",
    "\n",
    "for col, year in enumerate(years):\n",
    "    ax2 = axes[col].twinx()\n",
    "    precip_yearly.iloc[:, col].plot(ax=ax2, label='Precip', color='tab:green', linewidth=0.5)\n",
    "    if col == 0:\n",
    "        ax2.set_ylabel('Precipitation (mm/day)')\n",
    "        ax2.legend(loc='upper right', bbox_to_anchor=(1, 1.3), fancybox=True, ncol=1)\n",
    "    quality2.iloc[:, col].plot(ax=axes[col], color=colors[0], linewidth=2, label='Good provisional data')\n",
    "    quality3.iloc[:, col].plot(ax=axes[col], color=colors[1], linewidth=2, label='Good provisional data - edited')\n",
    "    quality8.iloc[:, col].plot(ax=axes[col], color=colors[2], linewidth=2, label='Below rating')\n",
    "    quality10.iloc[:, col].plot(ax=axes[col], color=colors[3], linewidth=2, label='Above rating (<2x)')\n",
    "    quality50.iloc[:, col].plot(ax=axes[col], color=colors[4], linewidth=2, label='Estimated')\n",
    "    quality77.iloc[:, col].plot(ax=axes[col], color=colors[5], linewidth=2, label='Estimated from other station')\n",
    "    quality160.iloc[:, col].plot(ax=axes[col], color=colors[6], linewidth=2, label='Above rating (>2x)')\n",
    "    quality161.iloc[:, col].plot(ax=axes[col], color=colors[7], linewidth=2, label='Below rating (<1/2x)')\n",
    "    quality179.iloc[:, col].plot(ax=axes[col], color=colors[8], linewidth=2, label='Estimated - unreliable')\n",
    "    quality254.iloc[:, col].plot(ax=axes[col], color=colors[9], linewidth=2, label='Rating exceeded')\n",
    "    runoff_obs_yearly.iloc[:, col].plot(ax=axes[col], label='Observed', linewidth=1)\n",
    "    runoff_sim_yearly.iloc[:, col].plot(ax=axes[col], label='Simulated', linewidth=1)\n",
    "    ax2.invert_yaxis()\n",
    "    axes[col].set_ylim([-5, 80])\n",
    "    axes[col].set_title(year)\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(0, 1.9), fancybox=True, ncol=2)\n",
    "axes[0].set_ylabel('Runoff (mm/day)')\n",
    "fig.suptitle('Fig. 3: Observed vs. VELMA simulated runoff (with precipitation and quality flags)')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('baseline_runoffs_qaflags.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding quality flags unreliable and extreme measurements, we can see that many of these are the peaks and troughs where VELMA performs the worst. This doesn't necessarily mean there is an error with the stream gauge, just flags the values as extra-ordinary. Does beg the question - is this the natural flashiness of Ellsworth that the rating table just didn't capture? Or is this the result of instrument error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing runoff gauge measurements with low-quality tags\n",
    "\n",
    "Imputing quality tags 160 (Above rating, over 2x), 161 (Below rating, less than 1/2x), and 254 (rating table exceeded).\n",
    "\n",
    "The imputation process involves training an SVR model using precipitation (and 1-day lag and 2-day sums), temperature (mean, min, max), and sin and cosine day of year. The model is trained on the runoff dataset with low-quality values removed. Then the trained model is used to predict the removed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSE for SVR test data: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12769544285958093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c6a367d3784007b32ce2b5e383fe7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imputing select (but not all) days with quality codes\n",
    "\n",
    "# Use model for runoff imputation to estimate removed values\n",
    "\n",
    "low_qual = quality[(quality['Quality'].isin([2, 254, 179, 161]))]\n",
    "\n",
    "flow = pd.read_csv(flow_path, usecols=['Date', 'Flow_cfs'], parse_dates=True, index_col=0)\n",
    "\n",
    "# Convert streamflow from cfs to mm/day\n",
    "# 2.446576 ft3/sec =  1m3/35.314667ft3 * 1/km2 * 86400sec/1day * 1km2/1000000m2 * 1000mm/1m\n",
    "ft3_sec = (1 / 35.314667) * 86400 * (1 / 1000000) * 1000\n",
    "area = 13.7393  # area of upstream Ellsworth watershed, sq. km\n",
    "flow['flow_mm_day'] = (flow['Flow_cfs'] / area) * ft3_sec\n",
    "flow.drop('Flow_cfs', axis=1, inplace=True)\n",
    "\n",
    "# Expand date range to include every day of all the years present\n",
    "begin = '01-01-{}'.format(flow.index.to_frame()['Date'].min().year)\n",
    "end = '12-31-{}'.format(flow.index.to_frame()['Date'].max().year)\n",
    "rng = pd.date_range(begin, end)\n",
    "df = pd.DataFrame(index=rng)\n",
    "daily_flow = df.merge(flow, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Feature engineering\n",
    "daily_precip_path = config.daily_ppt\n",
    "precip = pd.read_csv(str(daily_precip_path), parse_dates=True, index_col=0)\n",
    "daily_temp_mean_path = config.daily_temp_mean\n",
    "temp_mean = pd.read_csv(str(daily_temp_mean_path), parse_dates=True, index_col=0)\n",
    "daily_temp_min_path = config.daily_temp_min\n",
    "temp_mean_min = pd.read_csv(str(daily_temp_min_path), parse_dates=True, index_col=0)\n",
    "daily_temp_max_path = config.daily_temp_max\n",
    "temp_mean_max = pd.read_csv(str(daily_temp_max_path), parse_dates=True, index_col=0)\n",
    "df = pd.concat([precip, temp_mean, temp_mean_min, temp_mean_max], axis=1)\n",
    "\n",
    "# Convert day of year to signal\n",
    "day = 24 * 60 * 60\n",
    "year = 365.2425 * day\n",
    "timestamp_secs = pd.to_datetime(df.index)\n",
    "timestamp_secs = timestamp_secs.map(datetime.datetime.timestamp)\n",
    "df['year_cos'] = np.cos(timestamp_secs * (2 * np.pi / year))\n",
    "df['year_sin'] = np.sin(timestamp_secs * (2 * np.pi / year))\n",
    "\n",
    "# Sum of last 2 days precip\n",
    "df['precip_sum-2t'] = precip.rolling(2).sum()\n",
    "\n",
    "# Previous days' precip\n",
    "df['precip_t-1'] = precip['mean_ppt_mm'].shift(1)\n",
    "df['precip_t-2'] = precip['mean_ppt_mm'].shift(2)\n",
    "df['precip_t-3'] = precip['mean_ppt_mm'].shift(3)\n",
    "\n",
    "obs = df.merge(daily_flow['flow_mm_day'], left_index=True, right_index=True, how='right')\n",
    "\n",
    "# Set aside dates with missing flow measurements\n",
    "gap_data = obs[obs['flow_mm_day'].isna()]\n",
    "obs.dropna(inplace=True)\n",
    "\n",
    "# Remove days with low quality measurements\n",
    "shared_index = obs.index.intersection(low_qual.index)\n",
    "obs_highqual = obs.drop(shared_index)\n",
    "\n",
    "def plot_test_results(y_test, y_pred):\n",
    "    results = pd.DataFrame(data=np.column_stack([y_test, y_pred]), index=y_test.index, columns=['y_test', 'y_pred'])\n",
    "    results = (results * train_std['flow_mm_day']) + train_mean['flow_mm_day']\n",
    "    plt.plot(results)\n",
    "    plt.legend(results.columns)\n",
    "\n",
    "\n",
    "# Split the data 70-20-10\n",
    "n = obs_highqual.shape[0]\n",
    "train_df = obs_highqual[0:int(n * 0.7)]\n",
    "test_df = obs_highqual[int(n * 0.7):]\n",
    "num_features = obs_highqual.shape[1]\n",
    "\n",
    "cols = obs_highqual.columns.tolist()\n",
    "target = cols.index('flow_mm_day')\n",
    "\n",
    "# Normalize\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "\n",
    "X_train, y_train = train_df.iloc[:, 0:target], train_df.iloc[:, target]\n",
    "X_test, y_test = test_df.iloc[:, 0:target], test_df.iloc[:, target]\n",
    "\n",
    "svr = SVR(kernel='rbf', C=1, gamma='auto', epsilon=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "display('MSE for SVR test data: ', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "plt.figure()\n",
    "plot_test_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the trained model to impute the low-quality values, combine the results with the reliable original data, and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7616067519046d8ac996a99c9df176d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using trained model to imput the measurements removed for low quality\n",
    "\n",
    "velma_start = pd.to_datetime('01-01-2004')\n",
    "velma_end = pd.to_datetime('12-31-2007')\n",
    "\n",
    "# Remove dates with poor quality tags/rating table exceedances\n",
    "gap_data = low_qual.merge(df, left_index=True, right_index=True, how='left')\n",
    "gap_data_04_07 = gap_data[(gap_data.index >= velma_start) & (gap_data.index <= velma_end)].copy()\n",
    "X_gap = gap_data_04_07.drop(columns=['Quality'], axis=1)\n",
    "\n",
    "X_gap = (X_gap - train_mean[:-1]) / train_std[:-1]\n",
    "gap_pred = svr.predict(X_gap)\n",
    "gap_pred = (gap_pred * train_std['flow_mm_day']) + train_mean['flow_mm_day']\n",
    "\n",
    "gap_data_04_07['flow_mm_day'] = gap_pred\n",
    "\n",
    "# Combine imputed flow with observed data\n",
    "gap_data_04_07_imp = gap_data_04_07.drop(columns=['Quality', 'mean_ppt_mm', 'mean_temp_c', 'Mean', 'Mean', 'year_cos',\n",
    "                                                  'year_sin', 'precip_sum-2t', 'precip_t-1', 'precip_t-2',\n",
    "                                                  'precip_t-3'], axis=1).copy()\n",
    "gap_data_04_07_imp['doy'], gap_data_04_07_imp['year'] = gap_data_04_07_imp.index.dayofyear, gap_data_04_07_imp.index.year\n",
    "\n",
    "runoff_obs_drop = runoff_obs.drop(gap_data_04_07_imp.index)\n",
    "runoff_obs_drop = runoff_obs_drop.rename(columns={'runoff_obs': 'flow_mm_day'})\n",
    "runoff_obs_imp = pd.concat([runoff_obs_drop, gap_data_04_07_imp]).sort_index()\n",
    "\n",
    "# Plot imputed data vs. VELMA simulated data\n",
    "runoff_obs_imp_yearly = pd.pivot_table(runoff_obs_imp, index=['doy'], columns=['year'], values=['flow_mm_day'])\n",
    "\n",
    "# Plot average daily runoff vs. VELMA simulated runoff\n",
    "years = runoff_obs_imp_yearly.columns.get_level_values(1)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(years), figsize=(6, 9))\n",
    "for col, year in enumerate(years):\n",
    "    runoff_obs_imp_yearly.iloc[:, col].plot(ax=axes[col], label='Observed (imputed)', linewidth=1)\n",
    "    runoff_sim_yearly.iloc[:, col].plot(ax=axes[col], label='Simulated', linewidth=1)\n",
    "    axes[col].set_title(year)\n",
    "    axes[col].set_ylim([0, 80])\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(0, 1.3), fancybox=True, ncol=2)\n",
    "axes[0].set_ylabel('Runoff (mm/day)')\n",
    "fig.suptitle('Fig. 5: Observed vs. VELMA simulated runoff (imputed values)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NS (original runoff values): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46738813770737575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NS (low-quality values imputed): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4783450553077594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computing Nash-Sutcliffe\n",
    "def NS(s, o):\n",
    "    \"\"\"\n",
    "        Nash Sutcliffe efficiency coefficient\n",
    "        input:\n",
    "        s: simulated\n",
    "        o: observed\n",
    "        output:\n",
    "        ns: Nash Sutcliffe efficient coefficient\n",
    "        \"\"\"\n",
    "    # s,o = filter_nan(s,o)\n",
    "    return 1 - np.sum((s-o)**2)/np.sum((o-np.mean(o))**2)\n",
    "\n",
    "display('NS (original runoff values): ', NS(velma_results['Runoff_All(mm/day)_Delineated_Average'], runoff_obs['runoff_obs']))\n",
    "\n",
    "display('NS (low-quality values imputed): ', NS(velma_results['Runoff_All(mm/day)_Delineated_Average'], runoff_obs_imp['flow_mm_day']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unreliable runoff values and calculating Nash-Sutcliffe\n",
    "\n",
    "Imputation improves the fit significantly, but it also introduces quite a bit of uncertainty.\n",
    "\n",
    "What if we just removed the values that are the least reliable from computing Nash-Sutcliffe? The following quality flags were removed: \"Exceeded rating table (>2x)\" (160), \"Below rating table (<1/2x)\" (161), \"Estimated - unreliable\" (179)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "runoff_sim = velma_results['Runoff_All(mm/day)_Delineated_Average']\n",
    "df = pd.concat([runoff_sim, runoff_obs, quality], axis=1)\n",
    "df_edited = df.drop(df[(df['Quality'] == 50) | (df['Quality'] == 160) | (df['Quality'] == 161) | (df['Quality'] == 179)].index)\n",
    "df_edited = df.drop(df[(df['Quality'] == 160) | (df['Quality'] == 161) | (df['Quality'] == 179)].index)\n",
    "df_edited = df.drop(df[(df['Quality'] == 160) | (df['Quality'] == 161) | (df['Quality'] == 179) | (df['Quality'] == 254)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NSE (2004): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6005535538604774"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NSE (2005): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7509217791510732"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NSE (2006): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.054723354364196175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NSE (2007): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.579676568310854"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NSE (2004-2007): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46738813770737575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('NSE (2004): ', NS(runoff_sim_yearly.iloc[:, 0], runoff_obs_yearly.iloc[:, 0]))\n",
    "display('NSE (2005): ', NS(runoff_sim_yearly.iloc[:, 1], runoff_obs_yearly.iloc[:, 1]))\n",
    "display('NSE (2006): ', NS(runoff_sim_yearly.iloc[:, 2], runoff_obs_yearly.iloc[:, 2]))\n",
    "display('NSE (2007): ', NS(runoff_sim_yearly.iloc[:, 3], runoff_obs_yearly.iloc[:, 3]))\n",
    "display('NSE (2004-2007): ', NS(velma_results['Runoff_All(mm/day)_Delineated_Average'], runoff_obs['runoff_obs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NSE values after removing unreliable measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NS (2004): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6606872992039245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NS (2005): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8046441136760274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NS (2006): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4618962802219244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NS (2007): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.579676568310854"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NS (2004-2007): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5973812617184182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'RMSE (2004-2007): '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.6259125648075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2003-2007 runoff\n",
    "sim_yearly = pd.pivot_table(df_edited[['Runoff_All(mm/day)_Delineated_Average', 'doy', 'year']], \n",
    "                            index=['doy'], \n",
    "                            columns=['year'], \n",
    "                            values=['Runoff_All(mm/day)_Delineated_Average'])\n",
    "\n",
    "obs_yearly = pd.pivot_table(df_edited[['runoff_obs', 'doy', 'year']], \n",
    "                            index=['doy'], \n",
    "                            columns=['year'], \n",
    "                            values=['runoff_obs'])\n",
    "\n",
    "display('NS (2004): ', NS(sim_yearly.iloc[:, 0], obs_yearly.iloc[:, 0]))\n",
    "display('NS (2005): ', NS(sim_yearly.iloc[:, 1], obs_yearly.iloc[:, 1]))\n",
    "display('NS (2006): ', NS(sim_yearly.iloc[:, 2], obs_yearly.iloc[:, 2]))\n",
    "display('NS (2007): ', NS(sim_yearly.iloc[:, 3], obs_yearly.iloc[:, 3]))\n",
    "\n",
    "df_edited_04_07 = df_edited[(df_edited.index >= pd.to_datetime('2004-01-01'))]\n",
    "display('NS (2004-2007): ', NS(df_edited_04_07['Runoff_All(mm/day)_Delineated_Average'], df_edited_04_07['runoff_obs']))\n",
    "display('RMSE (2004-2007): ', np.sqrt(mean_squared_error(df_edited_04_07['Runoff_All(mm/day)_Delineated_Average'], df_edited_04_07['runoff_obs'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a2b9b18a024146a5b97a6f575c4827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "years = obs_yearly.columns.get_level_values(1)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(years), figsize=(6, 9))\n",
    "for col, year in enumerate(years):\n",
    "    obs_yearly.iloc[:, col].plot(ax=axes[col], label='Observed (imputed)', linewidth=1)\n",
    "    sim_yearly.iloc[:, col].plot(ax=axes[col], label='Simulated', linewidth=1)\n",
    "    axes[col].set_title(year)\n",
    "    axes[col].set_ylim([0, 80])\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(0, 1.3), fancybox=True, ncol=2)\n",
    "fig.suptitle('Fig. 6: Observed vs. VELMA simulated runoff (unreliable values removed)')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export runoff with quality flagged values as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runoff_quality = runoff_obs.merge(quality, left_index=True, right_index=True, how='left')\n",
    "# remove = runoff_quality.loc[(runoff_quality['Quality'] == 160) | (runoff_quality['Quality'] == 161) | (runoff_quality['Quality'] == 179)].index\n",
    "# runoff_quality.loc[remove,'runoff_obs'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = config.velma_data / 'runoff' / 'ellsworth_Q_2003_2007_dummy_flagged.csv'\n",
    "# runoff_quality['runoff_obs'].to_csv(outfile, index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnc_velma",
   "language": "python",
   "name": "tnc_velma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
